---
layout : single
title : "[RAG] 04. RAG 평가와 최적화. 12시까지 달려봅시다! - 다시 돌아온 AutoRAG"
categories : [RAG, LLM]
tag : [페스트캠퍼스, 테디노트]
---

#### 좋은 질문이란 무엇일까?
- RAG 평가의 관점에서 분별력이 높은 질문이 좋은 질문
- IRT(Item Response Theory): 분별도, 추측도, 난이도 산출 개념으로, 에듀테크에서 많이 사용
- 아직 RAG에서 이 개념을 적용하고 있진 않으나, 추후 적용 가능성 있음

#### [Bloom's Taxonomy](https://en.wikipedia.org/wiki/Bloom%27s_taxonomy)
- 불룸의 분류법은 학습 목표를 6단계의 계층적 수준으로 분류하는 체계
- 지식, 이해, 적용, 분석, 종합, 평가의 6단계로 구분
- 활용 목적
  - 효과적인 학습 경험 설계
  - 교육 목표에 필요한 이해도와 사고력 수준 평가
  - 교육과정, 평가, 교수법 구조화

#### RAG 시스템 개발 방법론
- 이전에는 RAG 시스템을 개발한 후 평가를 진행하는 방법론이 대부분임
- 요즘은 좋은 질문과 답변을 생성한 후, RAG 시스템을 고도화 하면서 시스템을 개발하는 방법론이 대세

#### Data Cleaning
- 불필요한 정보 제거: 페이지마다 반복되는 불필요한 정보 제거
- 불필요한 페이지 제거: 비어 있는 페이지, 내용과 상관 없는 페이지 제거
- NVIDIA NeMo-Curator: Nvidia에서 만든 평가 데이터 생성용 라이브러리
  - 중복 페이지 제거
  - unicode 전처리 기능
  - 이모지 제거 기능

#### Agent RAG (Modular RAG)
- RAG는 Agent의 Tool로 인식
- 많은 지식(document)을 담고 있는 RAG는 적은 지식을 담은 RAG보다 성능(precision, recall)이 떨어짐
- 적당한 양의 지식을 담은 RAG를 여러 개 생성하여 하나의 툴로 사용하는 것이 이상적인 방법으로 생각
- 작은 RAG들을 만들기 어려운 이유
  - 분류 Agent의 성능
  - 명확한 RAG 간의 분리 문제
  - 여러 RAG의 최적화 문제
- Advanced RAG가 Agent RAG 시대에 여전히 중요한 이유
  - Retrieval 자체는 보통 독립된 tool로서 존재
  - 작은 RAG는 Advanced RAG로 구성되어 있을 수 있음
- query를 보고 정답을 내뱉을 수 있는 최소한의 (elapsed time이 최소) 프레임워크를 알 수 있는 기능이 필요함

#### 추가질문
3. 파싱 후에 얼마나 잘됐는지 평가 할 수 있는 방법
4. RAGAS or LLM-as-a-judge 두 개를 활용해서 평가를 하려고하는데, system-prompt가 얼마나 좋은지 평가를 하려고 하는데, 어떤 방법으로 평가해야 하는가?
   - Meta Evaluation의 개념
