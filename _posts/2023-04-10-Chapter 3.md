---
layout : single
title : "[DeepLearningBasic] Chapter 3. 왜 우리는 인공 신경망을 공부해야 하는가?"
categories : [DeepLearning, DeepLearningBasic]
tag : [혁팬하임]
---

# 1. 인공 신경망, weight와 bias의 직관적 이해, 인공 신경망은 함수다!

#### 인공신경

* weight(중요도)를 곱하고 bias(민감도)와 함께 더하고, 액티베이션 함수에 통과
* 주어진 입력에 대한 원하는 출력이 나오도록 weight와 bias를 학습시켜야 함



#### 인공신경망

* 인공신경망은 함수로, 주어진 입력에 대해 원하는 출력이 나오도록 하는 함수를 알아내는 것
* 적절한 weight와 bias를 알아내는 것이 딥러닝의 목표



# 2. 선형 회귀, 개념부터 알고리즘까지 step by step

#### 선형회귀

* 입력과 출력 간의 관계(함수)를 선형으로 놓고 추정하는 것
* 처음보는 입력에 대해서도 적절한 출력을 얻기 위함
* Loss(= cost)를 최소화하는 최적의 중요도와 민감도를 찾아야 함
  * 이때, error의 합을 단순히 구할 경우, 문제가 됨
  * error의 값이 음수와 양수가 존재하기 때문에 합이 0이 될 수 있음
  * 그렇기에, error 제곱의 합이 최소화 되도록 Loss를 설정해야 함
  * 절대값과 제곱 방안 모두 사용해도 되는데, 제곱을 더 많이 사용함
    * 절대값과 제곱을 그래프로 그렸을 때, Loss가 최소가 되는 점에서 멀어질수록 제곱이 더 민감하게 반응하기 때문
    * 절대값을 사용했을 경우, 미분이 안되는 문제가 있으나, 해당 문제는 꺾이는 점의 미분은 0이다 라는 예외를 주면 모든 경우에서 미분이 가능하기 때문에, 적절하지 못함
    * 다양한 이유에서 MSE(제곱) Loss를 사용함
* Loss는 내가 풀고 싶은 문제에 맞게 잘 정의하는 것이 중요



# 3. Gradient descent

