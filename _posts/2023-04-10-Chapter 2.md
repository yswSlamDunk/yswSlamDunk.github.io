---
layout : single
title : "Chapter 2. 왜 현재 AI가 가장핫할까"
categories : [DeepLearning, DeepLearningBasic]
tag : [혁팬하임]
---

# 4. 자기지도 학습

* 데이터가 많을수록 무조건 좋은데, 정답을 알고 있는 데이터가 너무 적음
* 데이터를 만드는데 많은 비용이 들어감
* 위의 문제를 해결하기 위해 나타난 방법이 자기지도 학습으로, 진짜 풀려고 했던 문제 말고 다른 문제를 새롭게 정의해 풀어보는 방법
  * 예를 들면, 고양이와 강아지를 구별하려는 모델을 학습하고자 함
  * 그런데 고양이와 강아지를 구별해 놓은 데이터의 수가 매우 적음
  * 이런 경우, 이미지 내의 하나의 중심 패치를 선택하고, 해당 패치의 주변을 후보 패치로 만듦
  * 주변 패치 중 하나를 선택하고, 중심 패치과 주변 패치를 입력으로 놓았을 때, 주변 패치의 상대적 위치를 파악하도록 다른 문제를 학습하게 만듦
  * 다음 적은 정답지를 가지고 문제를 풀어보도록 하면, 아무것도 하지 않고 적은 정답지를 학습한 모델보다 좋은 성능을 가짐을 확인할 수 있음
* 데이터 안에서 self로 정답(label)을 만든다는 점에서 자기지도 학습으로 불림

* 과정

  1. pretext task 학습으로 pre-training

  2. downstream task(본래의 문제)를 풀기 위해 transfer learning 진행

* pretext task로 Context prediction 제안

  * https://arxiv.org/abs/1505.05192
  * https://arxiv.org/abs/2002.05709
    * 동일 데이터로부터 추출된 이미지의 출력값은 유사하게(attract)
    * 다른 데이터로부터 추출된 이미지의 출력값은 달라지게(repel)
