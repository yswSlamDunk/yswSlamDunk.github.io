---
layout : single
title : "[RAG] 05. RAGAS 합성 데이터셋"
categories : [RAG, LLM]
tag : [RAG, RAGAS, 평가 데이터]
---


## RAGAS 합성 데이터셋 생성 과정
RAGAS의 합성 데이터셋 생성 과정은 지식 그래프 구축 후 시나리오를 생성하여 데이터셋을 생성함

### 질의 종류 (Query Types)
* RAGAS에서 질의 종류는 필요 문서 갯수, 추상화 정도에 따라 구분되며 4개의 종류로 구성
  * 현재 ragas 코드에선 SingleHopAbstractQeury는 없음
* 필요 문서 기준
  * Single-Hop: 단일 문서가 필요한 경우
  * Multi-Hop: 복수 문서가 필요한 경우
* 추상화 정도 기준
  * Specific: 문서에 포함된 정보에 대한 구체적(specific)이고 사실이 기반한(fact-based) 질의
  * Abstract: 문서의 정보로부터 추상적(abstract)이거나 해석적인 설명(interpretive explanation)이 필요한 질의
* 가설
  * Combined(신규 추상화 정도): Specific과 Abstract가 복합으로 들어있는 질의

## 1. 지식 그래프 구축 및 변형
### 1) 초기 지식 그래프 구축
* langchain Document type의 값은 하나의 노드로 생성됨
* 초기 지식 그래프 구축 단계에선 graph의 edge는 생성되지 않음
* edge는 추후 RelationshipBuilder를 통해 자동으로 생성됨

### 2) 분기 설정
* 초기 그래프 노드의 page_content를 tiktoken 라이브러리를 활용하여 token의 수를 파악
* (0, 100), (101, 500), (501, 10000)의 범주를 기준으로 document의 token 분포를 파악
* 만약 (501, 10000)의 토큰 document가 25% 이상이면 headlinesSplitter를 포함한 분기 실행
* 만약 (101, 500)의 토큰 document가 25% 이상이면 summary_extractor를 포함한 분기 실행
* 각 분기에 대한 내용은 testset/tranforms/default.py에서 확인 가능

### 3) 문서 분할기 (Document Spliter)
* 개요
  * 입력으로 kg(knowledge graph)를 입력받고, nodes, relationships를 출력
  * custom spliter를 활용하여 문서(노드)를 청크로 분해 가능
* 필요성
  * 만약 문서의 크기가 너무 큰 경우, llm 모델의 token 제한에 영향을 미칠 수 있음
  * (추측) 불균형한 크기는 정보의 대표성(많은 정보로부터 추출한 내용이 전체를 충분히 나타내지 못하는 현상)을 유발 가능
* 절차
  1. knowledge graph가 입력으로 들어오면, knowledge의 노드를 추출
  2. 노드를 HeadlineSplitter.split을 통해 분할
     * ragas의 기본 코드는 Splitter를 상속받은 HeadlineSplitter가 document split을 진행
     * Splitter를 상속받는 CustomSplitter를 생성하여 document split 가능 
  3. HeadlineSplitter 절차
     * 토큰이 500 이상인 노드들을 HeadlineExtractor에 실행해, headline을 추출.
     * HeadlineSplitter에 들어가는 노드의 토큰이 500 이상인 경우에 진행함
     * headline을 기준으로 노드를 분할한 후, 적정크기(min_token, max_token)을 기준으로 분할
     * 분할 과정에서 child, next type의 relationships을 생성
       * child type은 원본 문서와 분할 chunk의 관계
       * next type은 chunk의 순서 관계

### 4) 추출기 (Extractor)
#### (1) LLM Based
1. SummaryExractor
  ```python
  class SummaryExtractorPrompt(PydanticPrompt[StringIO, StringIO]):
    instruction: str = "Summarize the given text in less than 10 sentences."
  ```
1. KeyphrasesExtractor: 키워드
  ```python
  class KeyphrasesExtractorPrompt(PydanticPrompt[TextWithExtractionLimit, Keyphrases]):
    instruction: str = "Extract top max_num keyphrases from the given text."
  ```
1. TitleExtractor
  ```python
  class TitleExtractorPrompt(PydanticPrompt[StringIO, StringIO]):
    instruction: str = "Extract the title of the given document."
  ```
1. HeadlinesExtractor
  ```python
  class HeadlinesExtractorPrompt(PydanticPrompt[TextWithExtractionLimit, Headlines]):
    instruction: str = (
        "Extract the most important max_num headlines from the given text that can be used to split the text into independent sections."
        "Focus on Level 2 and Level 3 headings."
    )
  ```
1. NERExtractor: 개체명
  ```python
  class NERPrompt(PydanticPrompt[TextWithExtractionLimit, NEROutput]):
  instruction: str = (
      "Extract the named entities from the given text, limiting the output to the top entities. "
      "Ensure the number of entities does not exceed the specified maximum."
  )
  ```
1. TopicDescriptionExtractor: 주제 설명
  ```python
  class TopicDescriptionPrompt(PydanticPrompt[StringIO, TopicDescription]):
    instruction: str = (
        "Provide a concise description of the main topic(s) discussed in the following text."
    )
  ```
1. ThemesAndConceptsExtractor: 테마 및 개념
  ```python
  class ThemesAndConceptsExtractorPrompt(PydanticPrompt[TextWithExtractionLimit, ThemesAndConcepts]):
    instruction: str = "Extract the main themes and concepts from the given text."
  ```
#### (2) ragex_based
1. Link
  ```python
  links_extractor_pattern = r"(?i)\b(?:https?://|www\.)\S+\b"
  links_extractor = RegexBasedExtractor(
  pattern=links_extractor_pattern, is_multiline=True, property_name="links")
  ```
1. Email
  ```python
  emails_extractor_pattern = r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+"
  emails_extractor = RegexBasedExtractor(
  pattern=emails_extractor_pattern, is_multiline=False, property_name="emails")
  ```
1. Markdown heading
  ```python
  markdown_headings_pattern = r"^(#{1,6})\s+(.*)"
  markdown_headings_extractor = RegexBasedExtractor(
  pattern=markdown_headings_pattern, is_multiline=True, property_name="headings")
  ```
#### (3) Embedding_based
```python
  embedding = self.embedding_model.embed_query(text)
  return self.property_name, embedding
```
 
### 5) 관계 구축자 (Relationship builder)
#### Cosine 방식
1. CosineSimilarityBuilder
   * 노드들의 속성(property_name: str = "emedding")에 대한 유사도를 CosineSimilarity 방식으로 계산
   * threshold 방식을 적용하여 threshold(0.9) 이상의 두 노드에 cosine_similarity type의 relation 생성
   * 타겟 속성을 지정할 수 없음
2. SummaryCosineSimilarityBuilder
   * 두 노드의 summary_embedding 속성간 cosine_similarity 계산
   * type이 DOCUMENT인 노드들만 사용
   * threshold는 0.1

#### Traditional 방식
1. JaccardSimilarityBuilder
   * 노드들의 속성(property_name: str = "entities")에 대한 유사도를 JaccardSimilarity 방식으로 계산
   * threshold 0.5 이상일 경우, jaccard_similarity type의 relation 생성
2. OverlapScoreBuilder
* 개요
  * 노드들의 속성(property_name: str = "entities")에서 특정 키(key_name: t.Optional[str] = None)에 대한 유사도를 계산
  * 자주 등장하는 키워드를 noise로 설정하여 제외한 후 DistanceMeasure 방식으로 계산
  * 거리 계산 방법
* DistanceMeasure.LEVENSHTEIN
  * 한 문자열을 다른 문자열로 변환하는데 필요한 최소 편집 횟수
  * 연산: 삽입, 삭제, 대체
  * 특징
    * 긴 텍스트에 효과적
    * 가장 일반적으로 사용되는 문자열 거리 측정 방법
    * 철자 오류 검출에 효과적
* DistanceMeasure.HAMMING
  * 같은 위치에 있는 문자가 다른 개수를 계산
  * 특징
    * 같은 길이의 문자열에만 적용 가능
    * 비트열 비교에 자주 사용
    * 오류 검출 코드에서 많이 사용
* DistanceMeasure.JARO
  * 문자 일치와 위치 변환을 고려한 거리 계산
  * 특징
    * 짧은 문자열에 효과적
    * 절차 오류에 강건함
    * 0(완전 불일치)에서 1(완전 일치) 사이의 값
* DistanceMeasure.JARO_WINKLER: 
  * Jaro Distance를 기반으로 하되, 접두사 일치에 가중치 부여
  * 특징
    * 접두사가 같은 문자열에 더 높은 유사도 점수 부여
    * 이름이나 단어 비교에 최적화
    * jaro보다 더 세밀한 구분 가능
#### 관계구축 절차
  1. _get_noisy_items: 노드의 속성의 특정 키에서 noisy_item을 생성
  2. 그래프 내의 모든 노드간 noisy_item이 아닌 item들을 비교
  3. 두 노드가 가지고 있는 item들을 거리 계산 방식으로 계산
  4. (1 - 거리) 값이 distance_threshold(0.9) 이상유무를 operlaps에 append
  5. _overlap_score를 통해 두 노드의 특정 속성, 키에 대한 similarity를 계산
  6. similarity가 threshold 이상인 경우, {self.property_name}_overlap type의 relationships 반환

## 2. 시나리오 및 데이터셋 생성
### 1) 페르소나 생성(persona.py, function: generate_personas_from_kgv)
* 노드 필터링 및 요약 추출
* cosine_similarity 기반 요약 embediding 군집
    * threshold가 0.75 이상일 경우 군집
* 군집의 크기 순으로 num_personas(파라미터)만큼 군집 추출
* 각 군집별 글자 수가 가장 많은 요약문을 representative_summary로 설정
* representative_summary를 활용하여 persona 생성

```python
class PersonaGenerationPrompt(PydanticPrompt[StringIO, Persona]):
instruction: str = (
    "Using the provided summary, generate a single persona who would likely "
    "interact with or benefit from the content. Include a unique name and a "
    "concise role description of who they are."
)  

# 출력
Persona(
  name="Digital Marketing Specialist",
  role_description="Focuses on engaging audiences and growing the brand online." )
```

### 2) 시나리오 생성(_generate_scenarios)
  * 절차
    1. 필요한 노드/클러스터 찾기(get_node_clusters)
       * summary_similarity type relation을 활용하여 유사 cluster 검색
         * find_indirect_clusters는 dfs 알고리즘을 기반으로 유사 node를 검색
         * depth_limit은 3으로 그래프에서 홉(관계 수)를 의미하며, 유사한 node를 최대 3개
         * 만약 A-B-C, A-B-D 이렇게 연결되어 있다면, 별개의 클러스터로 인식함
       * cluster의 노드와 child type의 relation을 가지고 있는 노드들도 검색
    2. 클러스터별 노드 테마 기반 concept 조합 생성
       ```python
       class ConceptCombinationPrompt(PydanticPrompt[ConceptsList, ConceptCombinations]):
        instruction: str = (
            "Form combinations by pairing concepts from at least two different lists.\n"
            "**Instructions:**\n"
            "- Review the concepts from each node.\n"
            "- Identify concepts that can logically be connected or contrasted.\n"
            "- Form combinations that involve concepts from different nodes.\n"
            "- Each combination should include at least one concept from two or more nodes.\n"
            "- List the combinations clearly and concisely.\n"
            "- Do not repeat the same combination more than once."
        )

        # 출력 예시
        examples: t.List[t.Tuple[ConceptsList, ConceptCombinations]] = [
            (
                ConceptsList(
                    lists_of_concepts=[
                        ["Artificial intelligence", "Automation"],  # Concepts from Node 1
                        ["Healthcare", "Data privacy"],  # Concepts from Node 2
                    ],
                    max_combinations=2,
                ),
                ConceptCombinations(
                    combinations=[
                        ["Artificial intelligence", "Healthcare"],
                        ["Automation", "Data privacy"],
                    ]
                ),
            )
        ]
       ```
    3. LLM을 활용해 테마와 페르소나 매칭하기(theme_persona_matching_prompt)
      ```python
      class ThemesPersonasMatchingPrompt(
        PydanticPrompt[ThemesPersonasInput, PersonaThemesMapping]
        ):
            instruction: str = (
                "Given a list of themes and personas with their roles, "
                "associate each persona with relevant themes based on their role description."
            )
            input_model: t.Type[ThemesPersonasInput] = ThemesPersonasInput
            output_model: t.Type[PersonaThemesMapping] = PersonaThemesMapping
            examples: t.List[t.Tuple[ThemesPersonasInput, PersonaThemesMapping]] = [
                (
                    ThemesPersonasInput(
                        themes=["Empathy", "Inclusivity", "Remote work"],
                        personas=[
                            Persona(
                                name="HR Manager",
                                role_description="Focuses on inclusivity and employee support.",
                            ),
                            Persona(
                                name="Remote Team Lead",
                                role_description="Manages remote team communication.",
                            ),
                        ],
                    ),
                    PersonaThemesMapping(
                        mapping={
                            "HR Manager": ["Inclusivity", "Empathy"],
                            "Remote Team Lead": ["Remote work", "Empathy"],
                        }
                    ),
                )
            ]
      ```
    4. 모든 가능한 조합 생성하기(prepare_combinations)
      ```python
      [
          # 첫 번째 개념 조합 ["인공지능", "자연어처리"]에 대한 가능한 시나리오
          {
              "combination": ["인공지능", "자연어처리"],
              "personas": [
                  Persona(name="AI 연구원", role_description="인공지능 알고리즘을 연구하는 전문가"),
                  Persona(name="언어학자", role_description="자연어 처리와 언어 분석을 연구하는 학자"),
                  Persona(name="소프트웨어 개발자", role_description="AI 애플리케이션을 개발하는 프로그래머")
              ],
              "nodes": [
                  # 첫 번째 노드 (인공지능 테마 포함)
                  Node(id=..., type=NodeType.DOCUMENT, properties={...}),
                  # 두 번째 노드 (자연어처리 테마 포함)
                  Node(id=..., type=NodeType.DOCUMENT, properties={...})
              ],
              "styles": [
                  QueryStyle.MISSPELLED, # 철자 오류
                  QueryStyle.PERFECT_GRAMMAR, # 완벽한 문법
                  QueryStyle.POOR_GRAMMAR, # 잘못된 문법
                  QueryStyle.WEB_SEARCH_LIKE #웹 검색 형태
              ],
              "lengths": [
                  QueryLength.LONG,
                  QueryLength.MEDIUM,
                  QueryLength.SHORT
              ]
          }
      ]
      ```
       
    5. 다양성을 고려하여 필요한 수만큼 샘플링하기(sample_combinations, sample_diverse_combinations)
      ```python
      [
          # 시나리오 1: "인공지능"+"자연어처리", AI 연구원, PERFECT_GRAMMAR, MEDIUM
          {
              "combination": ("인공지능", "자연어처리"),
              "persona": Persona(name="AI 연구원", role_description="인공지능 알고리즘을 연구하는 전문가"),
              "nodes": [Node(...), Node(...)],
              "style": QueryStyle.PERFECT_GRAMMAR,
              "length": QueryLength.MEDIUM
          },
          
          # 시나리오 2: "인공지능"+"자연어처리", 언어학자, MISSPELLED, MEDIUM
          {
              "combination": ("인공지능", "자연어처리"),
              "persona": Persona(name="언어학자", role_description="자연어 처리와 언어 분석을 연구하는 학자"),
              "nodes": [Node(...), Node(...)],
              "style": QueryStyle.MISSPELLED,
              "length": QueryLength.MEDIUM
          },
          
          # 시나리오 3: "인공지능"+"자연어처리", 소프트웨어 개발자, POOR_GRAMMAR, LONG
          {
              "combination": ("인공지능", "자연어처리"),
              "persona": Persona(name="소프트웨어 개발자", role_description="AI 애플리케이션을 개발하는 프로그래머"),
              "nodes": [Node(...), Node(...)],
              "style": QueryStyle.POOR_GRAMMAR,
              "length": QueryLength.LONG
          }
      ]
      ```
  * 결과
    * 어떤 노드를 사용할지
    * 어떤 테마에 대해 질문할지 
    * 어떤 페르소나가 질문할지
    * 어떤 스타일로 질문할지
    * 얼마나 길게 질문할지  

### 3) 질문/답변 생성
  ```python
  class QueryAnswerGenerationPrompt(
      PydanticPrompt[QueryConditions, GeneratedQueryAnswer]
  ):
      instruction: str = (
          "Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) "
          "and the provided context. The themes represent a set of phrases either extracted or generated from the "
          "context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query "
          "explicitly incorporates these themes."
          "### Instructions:\n"
          "1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining "
          "information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more "
          "themes and reflects their relevance to the context.\n"
          "2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to "
          "the query. Avoid adding information that is not directly present or inferable from the given context.\n"
          "3. **Multi-Hop Context Tags**:\n"
          "   - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n"
          "   - Ensure the query uses information from at least two segments and connects them meaningfully."
      )
      
      # 출력
      GeneratedQueryAnswer(
                query="How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?",
                answer=(
                    "The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming "
                    "the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory."
                ),
            ),
  ```

### 4) 데이터셋 생성  
```python
{
  "user_input": "딥러닝과 금용 분석이 어떻게 통합됬는지 설명해줘?",
  "reference": "딥러닝과 금융 분석은 여러 방식으로 통합되었습니다. 심층 신경망은 금융 시장 데이터의 복잡한 패턴을 인식하여 주가 예측, 리스크 분석, 사기 탐지에 활용됩니다. 특히 시계열 데이터 분석에는 LSTM이나 GRU와 같은 순환 신경망이 사용되며, 자연어 처리 기술은 뉴스와 소셜 미디어 감성 분석을 통해 시장 동향을 파악합니다. 또한 강화 학습은 자동화된 트레이딩 전략 개발에 적용되고 있습니다.",
  "reference_contexts": [
    "<1-hop>\n딥러닝은 인공 신경망을 여러 층으로 쌓아 복잡한 패턴을 학습하는 기계학습의 한 분야입니다. CNN, RNN, 트랜스포머 등 다양한 아키텍처가 있으며, 컴퓨터 비전, 자연어 처리, 음성 인식 등 여러 분야에서 혁신적인 성과를 내고 있습니다.",
    "<2-hop>\n금융 분석에서는 대량의 데이터를 활용하여 시장 동향 예측, 리스크 평가, 포트폴리오 최적화, 사기 탐지 등을 수행합니다. 전통적으로는 통계적 방법이 사용되었으나, 최근에는 머신러닝과 딥러닝 기술이 도입되어 더 정확한 예측과 패턴 인식이 가능해졌습니다. 특히 시계열 데이터 분석, 자연어 처리를 통한 뉴스 감성 분석, 강화 학습을 활용한 트레이딩 전략 개발 등에서 인공지능 기술이 활발히 적용되고 있습니다."
  ],
  "synthesizer_name": "multi_hop_specific_query_synthesizer",
  "metadata": {
    "persona": {
      "name": "금융 분석가",
      "role_description": "금융 시장과 투자 전략을 연구하는 전문가"
    },
    "query_style": "POOR_GRAMMAR",
    "query_length": "MEDIUM",
    "combinations": ["딥러닝", "금융분석"]
  }
}
```
   
### RAGAS 한계점
### 1. 기능 관점
* summary_similarity relation을 기준으로 시나리오를 생성하기에, 유사 주제에 대한 질문만 생성될 수 있음.(?)
  * entity 기반으로 검색하는 내용
  * 완전 다른 내용(entity는 관계가 있으나, summary가 완전 다른 내용)
* 페르소나에 entity를 추가하는 방법
### 2. 결과 관점
* https://www.youtube.com/watch?v=8y816qLfjRM&ab_channel=Allganize
* 위 영상은 Allganize 회사의 llm 평가 서비스에 대한 소개 내용으로, ragas에 대한 내용이 언급됨
* ragas에 대한 평가에서 answer correctness, similarity 점수가 미달하다고 판단
  * answer correctness: 전문가와 ragas가 평가한 정답과 오답의 일치율
  * answer similarity: 전문가와 ragas가 답변한 내용의 유사도
* Allganize는 여러 평가 서비스와 자체 프롬프트 기반 평가 방안을 Emsemble하여 자체 서비스를 구축함